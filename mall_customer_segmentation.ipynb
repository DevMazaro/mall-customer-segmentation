{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DevMazaro/mall-customer-segmentation/blob/main/mall_customer_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd841ad5",
      "metadata": {
        "id": "bd841ad5"
      },
      "source": [
        "# **Mall Customer Segmentation with clustering**\n",
        "\n",
        "##**Introduction**\n",
        "This notebook exemplifies customer segmentation using\n",
        "multiple clustering techniques, including K-Means, Hierarchical Clustering, and DBSCAN.\n",
        "The analysis aims to identify distinct customer segments and provide actionable business insights.\n",
        "\n",
        "Note: This uses the Mall Customer dataset, which is a commonly used dataset in data science\n",
        "education and Kaggle competitions.\n",
        "\n",
        "This analysis extends beyond just clustering to provide\n",
        "detailed business recommendations. The goal is to demonstrate how data can be used to guide strategic decisions rather than simply confirm pre formed ideas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4854f0fa",
      "metadata": {
        "id": "4854f0fa"
      },
      "outputs": [],
      "source": [
        "#Importing libraries to be used in this project\n",
        "\n",
        "#Data manipulation and analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Popular data visualization libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#Machine learning\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from scipy.cluster.hierarchy import fcluster\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "#Hierarchical clustering\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "\n",
        "# Set visualization style\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette('viridis')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#--- Load Data ---\n",
        "# Load the dataset from the file\n",
        "data = pd.read_csv('data/Mall_Customers.csv')\n",
        "\n",
        "# --- Basic Data Exploration and Analysis ---\n",
        "print(\"\\n--- Data Exploration and Analysis ---\\n\")\n",
        "\n",
        "# Basic information about the dataset\n",
        "print(\"Dataset Information:\")\n",
        "print(f\"Shape: {data.shape}\")\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(data.head(10))\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing Values:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Statistical summary of numerical features\n",
        "print(\"\\nStatistical Summary:\")\n",
        "print(data.describe())\n",
        "\n",
        "# Distribution of categorical variables\n",
        "print(\"\\nGender Distribution:\")\n",
        "gender_counts = data['Gender'].value_counts()\n",
        "print(gender_counts)\n",
        "print(f\"Percentage: {gender_counts / len(data) * 100}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Ces-zRiOGait",
        "outputId": "d2f11efc-7b79-4b8d-dae0-3e1c8fe04bc1"
      },
      "id": "Ces-zRiOGait",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data/Mall_Customers.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-928c317686ef>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#--- Load Data ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Load the dataset from the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/Mall_Customers.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# --- Basic Data Exploration and Analysis ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/Mall_Customers.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Data Exploration**\n",
        "Before jumping into clustering analysis, let's explore our dataset to understand the distribution of variables and relationships between features. This will help us make informed decisions about feature selection and clustering approaches."
      ],
      "metadata": {
        "id": "u9n3CX2lJLZt"
      },
      "id": "u9n3CX2lJLZt"
    },
    {
      "cell_type": "code",
      "source": [
        "# Doing some data visualization\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Age distribution\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.histplot(data['Age'], kde=True)\n",
        "plt.title('Age Distribution')\n",
        "\n",
        "# Annual Income distribution\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.histplot(data['Annual Income (k$)'], kde=True)\n",
        "plt.title('Annual Income Distribution')\n",
        "\n",
        "# Spending Score distribution\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.histplot(data['Spending Score (1-100)'], kde=True)\n",
        "plt.title('Spending Score Distribution')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fGNxSTDzzx5p"
      },
      "id": "fGNxSTDzzx5p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Any relationthip in the data?\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Relationship between Annual Income and Spending Score\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.scatterplot(x='Annual Income (k$)', y='Spending Score (1-100)', data=data, hue='Gender')\n",
        "plt.title('Annual Income vs Spending Score by Gender')\n",
        "\n",
        "# Age vs Annual Income\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.scatterplot(x='Age', y='Annual Income (k$)', data=data, hue='Gender')\n",
        "plt.title('Age vs Annual Income by Gender')\n",
        "\n",
        "# Age vs Spending Score\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.scatterplot(x='Age', y='Spending Score (1-100)', data=data, hue='Gender')\n",
        "plt.title('Age vs Spending Score by Gender')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dr7Loihd4VBh"
      },
      "id": "dr7Loihd4VBh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Look for correlations between numerical features\n",
        "plt.figure(figsize=(10, 8))\n",
        "correlation_matrix = data[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']].corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LZmAQdMK4dYh"
      },
      "id": "LZmAQdMK4dYh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Insights from Data Analysis (Before clustering)**\n",
        "* **Statistical data and Feature Distributions**\n",
        "   * **Age:**\n",
        "      * This dataset has data points from 18 to 70, but the highest concentration is on the \"I'm still young\" crowd (30 to 40 years)\n",
        "   * **Income:**\n",
        "      * Large range of data (15K to 137K), but no extreme outliers. We will still scale the data for clustering.\n",
        "      * Concentration on the 20K to 80K range, with a sharp drop after 80K\n",
        "   * **Spending Score:**\n",
        "      * Highest concentration right at the middle (50 points), but also has peaks around 20 points and 70-80 points. Perhaps there are 3 main kinds of customers (We will test that).\n",
        "* Scatter Plots:\n",
        "   * **Income vs. Spending Score:**\n",
        "      * This scatter plot alone almost shows 5 different clusters. This suggest these two features will be good for clustering.\n",
        "      * The scatter plot shows no correlation between income and spending score.\n",
        "   * **Income vs Age:**\n",
        "      * We see no clear relationship between income and age\n",
        "   * **Age vs. Spending score**\n",
        "       * Shows somewhat of a relationship with customer under 40 having a higher spending score that people older than 40.\n",
        "       * Also displays clustering potential, but not nearly as clear as Income vs. Spending Score.\n",
        "   * **Gender Analysis:**\n",
        "      * Dataset relatively well balanced (56% female, 44% male)\n",
        "      * The scatter plots show no indication of a clear separation between male and female."
      ],
      "metadata": {
        "id": "UK2IbCYF6nLR"
      },
      "id": "UK2IbCYF6nLR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Customer Segmentation with K-Means Clustering**\n",
        "Clustering is an unsupervised machine learning technique that groups similar data points together without predefined labels. The goal is to find natural patterns in customer behavior that can inform business strategies. By identifying distinct customer segments, businesses can tailor their marketing, product offerings, and customer experience to better serve different groups.\n",
        "\n",
        "<br>\n",
        "\n",
        "K-Means is one of the most popular clustering algorithms due to its simplicity and effectiveness. It works by dividing data into k clusters, where each point belongs to the cluster with the nearest center (centroid). The algorithm iteratively adjusts these centroids until it finds the optimal grouping. Based on our exploration, Annual Income and Spending Score showed the clearest potential for natural groupings, making them ideal features for our initial clustering approach."
      ],
      "metadata": {
        "id": "8WgoQx5ZM0zG"
      },
      "id": "8WgoQx5ZM0zG"
    },
    {
      "cell_type": "code",
      "source": [
        "# Select features for clustering based on exploration insights\n",
        "selected_features = data[['Annual Income (k$)', 'Spending Score (1-100)']]\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(selected_features)\n",
        "\n",
        "# Apply K-Means clustering with 5 clusters\n",
        "# (We'll validate this number in the next section)\n",
        "num_clusters = 5\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "data['Cluster'] = kmeans.fit_predict(scaled_data)\n",
        "\n",
        "print(f\"K-Means clustering completed with {num_clusters} clusters\")\n",
        "print(f\"Cluster distribution:\\n{data['Cluster'].value_counts().sort_index()}\")"
      ],
      "metadata": {
        "id": "sTqHjs4XlYUT"
      },
      "id": "sTqHjs4XlYUT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "05a9fe45",
      "metadata": {
        "id": "05a9fe45"
      },
      "source": [
        "##**Finding the Optimal Number of Clusters**\n",
        "Before settling on our cluster count, we need to validate that 5 clusters is actually optimal. Two key methods help us determine this: the Elbow Method and Silhouette Score.\n",
        "\n",
        "*   **Elbow Method:** This technique plots the within-cluster sum of squares (WCSS) against different numbers of clusters. We look for the \"elbow\" (the point where adding more clusters doesn't significantly reduce WCSS).\n",
        "\n",
        "*   **Silhouette Score:** This measures how well-separated our clusters are by comparing distances within clusters versus distances between clusters. Scores range from -1 to +1, where higher values indicate better-defined clusters. A score near +1 means points are close to their own cluster and far from others, while negative scores suggest points might be in the wrong cluster.\n",
        "\n",
        "Using both methods together gives us confidence in our cluster count choice, ensuring we're not over-segmenting or missing important customer groups."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27de011e",
      "metadata": {
        "id": "27de011e"
      },
      "outputs": [],
      "source": [
        "# Elbow Method - Calculate WCSS for different cluster numbers\n",
        "wcss = []\n",
        "for i in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42, n_init=10)\n",
        "    kmeans.fit(scaled_data)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, 11), wcss, marker='o', linewidth=2)\n",
        "plt.title('Elbow Method for Optimal Number of Clusters')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('WCSS (Within-Cluster Sum of Squares)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5914aaa5",
      "metadata": {
        "id": "5914aaa5"
      },
      "outputs": [],
      "source": [
        "# Silhouette Score Analysis\n",
        "silhouette_scores = []\n",
        "for i in range(2, 11):\n",
        "    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42, n_init=10)\n",
        "    kmeans.fit(scaled_data)\n",
        "    score = silhouette_score(scaled_data, kmeans.labels_)\n",
        "    silhouette_scores.append(score)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(2, 11), silhouette_scores, marker='o', linewidth=2, color='green')\n",
        "plt.title('Silhouette Score for Different Numbers of Clusters')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Conclusion:**Both the elbow method and silhouette score indicate that 5 clusters is the optimal number of clusters"
      ],
      "metadata": {
        "id": "AA-XZkNhlUSv"
      },
      "id": "AA-XZkNhlUSv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Visualizing Customer Segments**\n",
        "Now let's see our clusters in action! The scatter plot below shows how K-Means has divided our customers into 5 distinct segments based on their income and spending patterns. The red X marks show the centroids (centers) of each cluster."
      ],
      "metadata": {
        "id": "b_tAdAIQYAyQ"
      },
      "id": "b_tAdAIQYAyQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce28b031",
      "metadata": {
        "id": "ce28b031"
      },
      "outputs": [],
      "source": [
        "#Refiting the model to 5 clusters\n",
        "num_clusters = 5\n",
        "kmeans = KMeans(n_clusters=num_clusters, init='k-means++', random_state=42)\n",
        "data['Cluster'] = kmeans.fit_predict(scaled_data)\n",
        "\n",
        "# Visualize the K-Means clustering results\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(data['Annual Income (k$)'], data['Spending Score (1-100)'],\n",
        "            c=data['Cluster'], cmap='viridis', s=60, alpha=0.8)\n",
        "\n",
        "# Plot the centroids\n",
        "centroids = scaler.inverse_transform(kmeans.cluster_centers_)\n",
        "plt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=200, alpha=0.9,\n",
        "           marker='X', label='Centroids', edgecolors='black', linewidth=1)\n",
        "\n",
        "plt.title('Customer Segments based on Annual Income and Spending Score', fontsize=14)\n",
        "plt.xlabel('Annual Income (k$)', fontsize=12)\n",
        "plt.ylabel('Spending Score (1-100)', fontsize=12)\n",
        "plt.colorbar(label='Cluster')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Looking into the statistics of the clusters\n",
        "cluster_analysis = data.groupby('Cluster').agg({\n",
        "    'Annual Income (k$)': ['mean', 'min', 'max', 'count'],\n",
        "    'Spending Score (1-100)': ['mean', 'min', 'max'],\n",
        "    'Age': 'mean',\n",
        "    'Gender': lambda x: x.value_counts().to_dict()\n",
        "}).round(2)\n",
        "\n",
        "print(\"Cluster Analysis:\")\n",
        "print(cluster_analysis)"
      ],
      "metadata": {
        "id": "QiE8WQjOpurX"
      },
      "id": "QiE8WQjOpurX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Hierarchical Clustering Analysis**\n",
        "Let's compare our K-Means results with hierarchical clustering, which builds clusters by progressively merging or splitting groups based on similarity. Unlike K-Means, hierarchical clustering doesn't require us to specify the number of clusters upfront - we can visualize the entire clustering process through a dendrogram and then decide where to \"cut\" the tree to get our desired number of clusters."
      ],
      "metadata": {
        "id": "JlTrzExzvbHM"
      },
      "id": "JlTrzExzvbHM"
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform hierarchical clustering using Ward linkage\n",
        "Z = linkage(scaled_data, 'ward')\n",
        "\n",
        "# Create a dendrogram to visualize the hierarchical structure\n",
        "plt.figure(figsize=(15, 8))\n",
        "plt.title('Hierarchical Clustering Dendrogram', fontsize=14)\n",
        "plt.xlabel('Sample Index', fontsize=12)\n",
        "plt.ylabel('Distance', fontsize=12)\n",
        "\n",
        "# Draw the dendrogram\n",
        "dendrogram(Z, leaf_rotation=90, leaf_font_size=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R1WcMcb1t76s"
      },
      "id": "R1WcMcb1t76s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Creating Hierarchical Clusters**\n",
        "Based on the dendrogram, we can see natural break points where clusters merge. Let's cut the tree at a distance that gives us 5 clusters to match our K-Means analysis."
      ],
      "metadata": {
        "id": "mHd652I4bZsX"
      },
      "id": "mHd652I4bZsX"
    },
    {
      "cell_type": "code",
      "source": [
        "# Cut the dendrogram to create 5 clusters\n",
        "threshold = 4.5\n",
        "hierarchical_clusters = fcluster(Z, threshold, criterion='distance')\n",
        "\n",
        "# Add the cluster labels to the dataframe\n",
        "data['Hierarchical_Cluster'] = hierarchical_clusters\n",
        "\n",
        "print(f\"Hierarchical clustering completed with {len(set(hierarchical_clusters))} clusters\")\n",
        "print(f\"Cluster distribution:\\n{pd.Series(hierarchical_clusters).value_counts().sort_index()}\")"
      ],
      "metadata": {
        "id": "Ydr_CKYFxmJt"
      },
      "id": "Ydr_CKYFxmJt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Hierarchical Clustering Results**\n",
        "Now let's examine how hierarchical clustering has segmented our customers and analyze the cluster characteristics."
      ],
      "metadata": {
        "id": "5z-GqaQ7bm8c"
      },
      "id": "5z-GqaQ7bm8c"
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize hierarchical clustering results\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(data['Annual Income (k$)'], data['Spending Score (1-100)'],\n",
        "            c=data['Hierarchical_Cluster'], cmap='viridis', s=60, alpha=0.8)\n",
        "\n",
        "plt.title('Hierarchical Clustering Results', fontsize=14)\n",
        "plt.xlabel('Annual Income (k$)', fontsize=12)\n",
        "plt.ylabel('Spending Score (1-100)', fontsize=12)\n",
        "plt.colorbar(label='Cluster')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6ZKxlRdX06Dn"
      },
      "id": "6ZKxlRdX06Dn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze hierarchical clustering results\n",
        "hierarchical_analysis = data.groupby('Hierarchical_Cluster').agg({\n",
        "    'Annual Income (k$)': ['mean', 'min', 'max', 'count'],\n",
        "    'Spending Score (1-100)': ['mean', 'min', 'max'],\n",
        "    'Age': 'mean',\n",
        "    'Gender': lambda x: x.value_counts().to_dict()\n",
        "}).round(2)\n",
        "\n",
        "print(\"Hierarchical Clustering Analysis:\")\n",
        "print(hierarchical_analysis)"
      ],
      "metadata": {
        "id": "EYegMeo44y9L"
      },
      "id": "EYegMeo44y9L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**DBSCAN Clustering Analysis**\n",
        "DBSCAN (Density-Based Spatial Clustering of Applications with Noise) takes a different approach from K-Means and Hierarchical clustering. Instead of forcing every point into a cluster, DBSCAN identifies dense regions and can classify some points as \"noise\" or outliers. This makes it particularly useful for finding clusters of varying shapes and identifying customers who don't fit typical patterns. DBSCAN requires two key parameters: eps (the maximum distance between points in the same neighborhood) and min_samples (the minimum number of points needed to form a cluster core)."
      ],
      "metadata": {
        "id": "xpqFaQvf0R8M"
      },
      "id": "xpqFaQvf0R8M"
    },
    {
      "cell_type": "code",
      "source": [
        "# Find optimal eps parameter using k-distance graph\n",
        "# We'll look for the \"elbow\" point where distance increases sharply\n",
        "k = 5  # Typically k = min_samples for DBSCAN\n",
        "neigh = NearestNeighbors(n_neighbors=k)\n",
        "neigh.fit(scaled_data)\n",
        "distances, indices = neigh.kneighbors(scaled_data)\n",
        "\n",
        "# Sort distances to k-th nearest neighbor\n",
        "distances = np.sort(distances[:, k-1], axis=0)\n",
        "\n",
        "# Plot k-distance graph to identify optimal eps\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(len(distances)), distances, linewidth=2)\n",
        "plt.xlabel('Points sorted by distance', fontsize=12)\n",
        "plt.ylabel(f'{k}-NN Distance', fontsize=12)\n",
        "plt.title('K-Distance Graph for DBSCAN eps Parameter Selection', fontsize=14)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aZI6NqGZWOID"
      },
      "id": "aZI6NqGZWOID",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Applying DBSCAN with Optimal Parameters**\n",
        "Based on the k-distance graph, we can identify the optimal eps value where the distance curve shows a sharp increase (the \"elbow\" point)."
      ],
      "metadata": {
        "id": "ZLejVGKYoJz-"
      },
      "id": "ZLejVGKYoJz-"
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply DBSCAN with parameters identified from k-distance graph\n",
        "eps = 0.40  # Distance threshold based on elbow in k-distance plot\n",
        "min_samples = 5  # Minimum number of points to form a dense region\n",
        "\n",
        "dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "data['DBSCAN_Cluster'] = dbscan.fit_predict(scaled_data)\n",
        "\n",
        "# Count clusters and noise points\n",
        "n_clusters = len(set(data['DBSCAN_Cluster'])) - (1 if -1 in data['DBSCAN_Cluster'] else 0)\n",
        "n_noise = list(data['DBSCAN_Cluster']).count(-1)\n",
        "\n",
        "print(f'Number of DBSCAN clusters: {n_clusters}')\n",
        "print(f'Number of noise points: {n_noise}')\n",
        "print(f'DBSCAN cluster distribution:\\n{data[\"DBSCAN_Cluster\"].value_counts().sort_index()}')"
      ],
      "metadata": {
        "id": "wCiPIzUxMczq"
      },
      "id": "wCiPIzUxMczq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**DBSCAN Results Visualization**\n",
        "Let's visualize how DBSCAN has segmented our customers. Notice that DBSCAN can identify outliers as \"noise\" points (shown in gray), which represents customers with unusual spending patterns."
      ],
      "metadata": {
        "id": "Tfy17RXHoavG"
      },
      "id": "Tfy17RXHoavG"
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize DBSCAN clustering results\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Plot each cluster with different colors\n",
        "unique_clusters = sorted(set(data['DBSCAN_Cluster']))\n",
        "colors = plt.cm.viridis(np.linspace(0, 1, len(unique_clusters)))\n",
        "\n",
        "for i, cluster in enumerate(unique_clusters):\n",
        "    cluster_data = data[data['DBSCAN_Cluster'] == cluster]\n",
        "\n",
        "    if cluster == -1:  # Noise points\n",
        "        plt.scatter(cluster_data['Annual Income (k$)'],\n",
        "                   cluster_data['Spending Score (1-100)'],\n",
        "                   c='gray', label='Noise', s=60, alpha=0.6, marker='x')\n",
        "    else:  # Regular clusters\n",
        "        plt.scatter(cluster_data['Annual Income (k$)'],\n",
        "                   cluster_data['Spending Score (1-100)'],\n",
        "                   c=[colors[i]], label=f'Cluster {cluster}', s=60, alpha=0.8)\n",
        "\n",
        "plt.title('DBSCAN Clustering Results', fontsize=14)\n",
        "plt.xlabel('Annual Income (k$)', fontsize=12)\n",
        "plt.ylabel('Spending Score (1-100)', fontsize=12)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k71XGmNwNWlm"
      },
      "id": "k71XGmNwNWlm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze DBSCAN cluster characteristics\n",
        "dbscan_analysis = data.groupby('DBSCAN_Cluster').agg({\n",
        "    'Annual Income (k$)': ['mean', 'min', 'max', 'count'],\n",
        "    'Spending Score (1-100)': ['mean', 'min', 'max'],\n",
        "    'Age': 'mean',\n",
        "    'Gender': lambda x: x.value_counts().to_dict()\n",
        "}).round(2)\n",
        "\n",
        "print(\"DBSCAN Cluster Analysis:\")\n",
        "print(dbscan_analysis)"
      ],
      "metadata": {
        "id": "HiKVc0BKojG9"
      },
      "id": "HiKVc0BKojG9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Comparing All Three Clustering Methods**\n",
        "Now let's examine how K-Means, Hierarchical Clustering, and DBSCAN have segmented our customers. We'll compare their statistical summaries and visualize all three approaches side-by-side to understand their differences and strengths."
      ],
      "metadata": {
        "id": "YYz-7839pa7V"
      },
      "id": "YYz-7839pa7V"
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare statistics across all three clustering methods\n",
        "print(\"=== K-MEANS CLUSTERING ANALYSIS ===\")\n",
        "kmeans_analysis = data.groupby('Cluster').agg({\n",
        "    'Annual Income (k$)': ['mean', 'min', 'max', 'count'],\n",
        "    'Spending Score (1-100)': ['mean', 'min', 'max'],\n",
        "    'Age': 'mean',\n",
        "    'Gender': lambda x: x.value_counts().to_dict()\n",
        "}).round(2)\n",
        "print(kmeans_analysis)\n",
        "\n",
        "print(\"\\n=== HIERARCHICAL CLUSTERING ANALYSIS ===\")\n",
        "hierarchical_analysis = data.groupby('Hierarchical_Cluster').agg({\n",
        "    'Annual Income (k$)': ['mean', 'min', 'max', 'count'],\n",
        "    'Spending Score (1-100)': ['mean', 'min', 'max'],\n",
        "    'Age': 'mean',\n",
        "    'Gender': lambda x: x.value_counts().to_dict()\n",
        "}).round(2)\n",
        "print(hierarchical_analysis)\n",
        "\n",
        "print(\"\\n=== DBSCAN CLUSTERING ANALYSIS ===\")\n",
        "dbscan_analysis = data.groupby('DBSCAN_Cluster').agg({\n",
        "    'Annual Income (k$)': ['mean', 'min', 'max', 'count'],\n",
        "    'Spending Score (1-100)': ['mean', 'min', 'max'],\n",
        "    'Age': 'mean',\n",
        "    'Gender': lambda x: x.value_counts().to_dict()\n",
        "}).round(2)\n",
        "print(dbscan_analysis)"
      ],
      "metadata": {
        "id": "fiPXW1_CplBt"
      },
      "id": "fiPXW1_CplBt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize all three clustering methods side-by-side\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# K-Means Plot\n",
        "axes[0].scatter(data['Annual Income (k$)'], data['Spending Score (1-100)'],\n",
        "                c=data['Cluster'], cmap='viridis', s=50, alpha=0.8)\n",
        "axes[0].scatter(centroids[:, 0], centroids[:, 1], c='red', s=200, alpha=0.9,\n",
        "                marker='X', edgecolors='black', linewidth=1)\n",
        "axes[0].set_title('K-Means Clustering', fontsize=14)\n",
        "axes[0].set_xlabel('Annual Income (k$)', fontsize=12)\n",
        "axes[0].set_ylabel('Spending Score (1-100)', fontsize=12)\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Hierarchical Plot\n",
        "axes[1].scatter(data['Annual Income (k$)'], data['Spending Score (1-100)'],\n",
        "                c=data['Hierarchical_Cluster'], cmap='viridis', s=50, alpha=0.8)\n",
        "axes[1].set_title('Hierarchical Clustering', fontsize=14)\n",
        "axes[1].set_xlabel('Annual Income (k$)', fontsize=12)\n",
        "axes[1].set_ylabel('Spending Score (1-100)', fontsize=12)\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# DBSCAN Plot\n",
        "unique_clusters = sorted(set(data['DBSCAN_Cluster']))\n",
        "colors = plt.cm.viridis(np.linspace(0, 1, len(unique_clusters)))\n",
        "\n",
        "for i, cluster in enumerate(unique_clusters):\n",
        "    cluster_data = data[data['DBSCAN_Cluster'] == cluster]\n",
        "\n",
        "    if cluster == -1:  # Noise points\n",
        "        axes[2].scatter(cluster_data['Annual Income (k$)'],\n",
        "                       cluster_data['Spending Score (1-100)'],\n",
        "                       c='gray', s=50, alpha=0.6, marker='x')\n",
        "    else:  # Regular clusters\n",
        "        axes[2].scatter(cluster_data['Annual Income (k$)'],\n",
        "                       cluster_data['Spending Score (1-100)'],\n",
        "                       c=[colors[i]], s=50, alpha=0.8)\n",
        "\n",
        "axes[2].set_title('DBSCAN Clustering', fontsize=14)\n",
        "axes[2].set_xlabel('Annual Income (k$)', fontsize=12)\n",
        "axes[2].set_ylabel('Spending Score (1-100)', fontsize=12)\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ql6Q4LlXprQ0"
      },
      "id": "ql6Q4LlXprQ0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Clustering Methods Comparison and Customer Segment Analysis**\n",
        "\n",
        "Our comprehensive analysis of three clustering techniques reveals distinct strengths and applications for customer segmentation. K-Means and Hierarchical clustering produced remarkably similar results, identifying virtually identical customer segments with only minimal differences in cluster boundaries. This convergence validates the natural groupings present in our customer data and provides confidence in our segmentation approach.\n",
        "\n",
        "## K-Means vs Hierarchical Clustering: Strong Convergence\n",
        "\n",
        "Both methods successfully identified five distinct customer segments with nearly identical characteristics. The slight variations in cluster membership (typically 1-4 customers per segment) demonstrate the robustness of these natural groupings. K-Means provided cleaner, more balanced clusters due to its optimization of within-cluster variance, while Hierarchical clustering offered insights into the natural merger process through its dendrogram visualization.\n",
        "\n",
        "<br>\n",
        "\n",
        "| K-means Cluster | Hierarchical Cluster | Customer Segment Description |\n",
        "| --- | --- | --- |\n",
        "| Cluster 0 | Cluster 5 | Middle-income, Moderate spenders |\n",
        "| Cluster 1 | Cluster 1 | High-income, High spenders |\n",
        "| Cluster 2 | Cluster 3 | Low-income, High spenders |\n",
        "| Cluster 3 | Cluster 2 | High-income, Low spenders |\n",
        "| Cluster 4 | Cluster 4 | Low-income, Low spenders |\n",
        "\n",
        "<br>\n",
        "\n",
        "## DBSCAN Analysis: Limitations for This Dataset\n",
        "\n",
        "While DBSCAN excels at finding clusters with irregular shapes and varying densities, our analysis revealed significant limitations for this particular customer dataset. DBSCAN's density-based approach suffered from chaining effects where data points created bridges between distinct customer groups, leading to cluster overgrowth and inappropriate mergers. The algorithm's parameter sensitivity made it challenging to achieve optimal segmentation - reducing eps created excessive noise points, while increasing it merged clearly separate customer segments. For our structured, well-separated customer data, K-Means proved superior in creating meaningful, actionable segments."
      ],
      "metadata": {
        "id": "ndm8zYbGtK0X"
      },
      "id": "ndm8zYbGtK0X"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Customer Segment Analysis Using K-Means Results**\n",
        "\n",
        "## Segment 1 - Standard Shoppers (Cluster 0): The Foundation\n",
        "\n",
        "**Statistical Characteristics:**\n",
        "- Size: 81 customers (40.5% of customer base)\n",
        "- Average age: 42.72 years\n",
        "- Gender distribution: 59% female, 41% male\n",
        "- Income range: \\$39k-\\$76k (average: \\$55,300)\n",
        "- Spending score range: 34-61 (average: 49.52)\n",
        "\n",
        "**Customer Profile:** This largest segment represents typical mall customers with moderate income and balanced spending patterns. These customers are generally middle-aged and include more women than men. They exhibit consistent but controlled spending behavior, likely making regular purchases without excessive splurging.\n",
        "\n",
        "**Strategic Implications:** As the largest customer segment, these shoppers form the backbone of the mall's revenue. They respond well to:\n",
        "- Value-based offerings and loyalty programs\n",
        "- Mid-range price points\n",
        "- Cross-promotional campaigns across various store types\n",
        "- Seasonal marketing initiatives\n",
        "\n",
        "### Segment 2 - Premium Shoppers (Cluster 1): The Revenue Drivers\n",
        "\n",
        "**Statistical Characteristics:**\n",
        "- Size: 39 customers (19.5% of customer base)\n",
        "- Average age: 32.69 years (youngest affluent group)\n",
        "- Gender distribution: Nearly balanced (54% female, 46% male)\n",
        "- Income range: \\$69k-\\$137k (average: \\$86,540)\n",
        "- Spending score range: 63-97 (average: 82.13)\n",
        "\n",
        "**Customer Profile:** These younger affluent professionals combine high income with high spending propensity. They represent the mall's most valuable customer segment, with both the means and desire to spend generously. Their balanced gender ratio suggests this segment includes young professionals and possibly DINKs (Double Income, No Kids).\n",
        "\n",
        "**Strategic Implications:** This segment should be the primary target for premium offerings:\n",
        "- Premium brands and luxury services\n",
        "- High-end promotions and exclusive events\n",
        "- Quality-focused and brand prestige marketing\n",
        "- Exceptional shopping experiences\n",
        "- Despite being only 19.5% of customers, they likely contribute disproportionately to revenue and profit\n",
        "\n",
        "### Segment 3 - Fashion-Forward Youth (Cluster 2): High Potential Despite Budget Constraints\n",
        "\n",
        "**Statistical Characteristics:**\n",
        "- Size: 22 customers (11% of customer base)\n",
        "- Average age: 25.27 years (youngest overall group)\n",
        "- Gender distribution: 59% female, 41% male\n",
        "- Income range: \\$15k-\\$39k (average: \\$25,730)\n",
        "- Spending score range: 61-99 (average: 79.36)\n",
        "\n",
        "**Customer Profile:** Despite having the lowest income among all segments, these young shoppers maintain high spending scores. They represent trend-conscious consumers who prioritize shopping despite budget constraints, likely allocating a high percentage of their disposable income to mall purchases. This group might include students and entry-level workers who place high value on fashion and social shopping experiences.\n",
        "\n",
        "**Strategic Implications:** This segment responds well to youth-oriented strategies:\n",
        "- Trendy, affordable fashion options\n",
        "- Social media marketing campaigns\n",
        "- Budget-friendly versions of current trends\n",
        "- Installment payment options and student discounts\n",
        "- Flash sales and limited-time offers\n",
        "- High long-term value as earning power increases\n",
        "\n",
        "### Segment 4 - Affluent Conservatives (Cluster 3): The Opportunity Gap\n",
        "\n",
        "**Statistical Characteristics:**\n",
        "- Size: 35 customers (17.5% of customer base)\n",
        "- Average age: 41.11 years\n",
        "- Gender distribution: 54% male, 46% female\n",
        "- Income range: \\$70k-\\$137k (average: \\$88,200)\n",
        "- Spending score range: 1-39 (average: 17.11)\n",
        "\n",
        "**Customer Profile:** With the highest average income but lowest spending scores, these customers are financially able but unwilling to spend at the mall. This middle-aged group has more men than women and represents value-conscious shoppers who likely make deliberate, researched purchases. They may visit the mall infrequently or for very specific purchases only.\n",
        "\n",
        "**Strategic Implications:** This segment represents significant untapped potential:\n",
        "- Rational appeals emphasizing value, quality, and durability\n",
        "- Investment pieces and premium services\n",
        "- Exclusive events and personalized shopping experiences\n",
        "- Evidence-based marketing highlighting product benefits\n",
        "- Focus on converting high-income, low-engagement customers\n",
        "\n",
        "### Segment 5 - Budget Conservatives (Cluster 4): The Practical Shoppers\n",
        "\n",
        "**Statistical Characteristics:**\n",
        "- Size: 23 customers (11.5% of customer base)\n",
        "- Average age: 45.22 years (oldest group)\n",
        "- Gender distribution: 61% female, 39% male\n",
        "- Income range: \\$15k-\\$39k (average: \\$26,300)\n",
        "- Spending score range: 3-40 (average: 20.91)\n",
        "\n",
        "**Customer Profile:** This segment combines low income with low spending propensity. These older shoppers are likely on fixed or limited incomes and exhibit highly conservative spending behavior. They may visit the mall primarily for necessities, heavily discounted items, or specific essential purchases.\n",
        "\n",
        "**Strategic Implications:** While not high-revenue generators, they respond to practical approaches:\n",
        "- Budget-friendly offerings and substantial discounts\n",
        "- Essential services and practical value propositions\n",
        "- Clearance sales and necessity-focused marketing\n",
        "- Purposeful, need-based shopping experiences\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "K-Means clustering proved most effective for this customer segmentation analysis, providing clear, actionable insights into five distinct customer groups. Each segment requires tailored marketing strategies and service offerings to maximize customer satisfaction and business profitability. The convergence between K-Means and Hierarchical clustering validates these natural customer groupings, while DBSCAN's limitations highlight the importance of selecting appropriate clustering methods based on data characteristics and business objectives."
      ],
      "metadata": {
        "id": "GRmm3JojxI5P"
      },
      "id": "GRmm3JojxI5P"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Business Considerations and Implementation Strategies\n",
        "\n",
        "## Customer Segment Implementation Strategies\n",
        "\n",
        "### Segment-Specific Marketing Approaches\n",
        "\n",
        "**Standard Shoppers (40.5% of customers):**\n",
        "- Implement comprehensive loyalty program with tier benefits\n",
        "- Focus on family-oriented promotions and seasonal campaigns\n",
        "- Utilize email marketing with value-focused messaging\n",
        "- Cross-promote complementary stores and services\n",
        "\n",
        "**Premium Shoppers (19.5% of customers):**\n",
        "- Create VIP shopping experiences and exclusive events\n",
        "- Implement personal shopping services and concierge programs\n",
        "- Partner with luxury brands for exclusive launches\n",
        "- Offer premium parking and express checkout services\n",
        "\n",
        "**Fashion-Forward Youth (11% of customers):**\n",
        "- Develop strong social media presence and influencer partnerships\n",
        "- Create Instagram-worthy spaces and photo opportunities\n",
        "- Implement mobile-first marketing strategies\n",
        "- Offer flexible payment options and student discounts\n",
        "\n",
        "**Affluent Conservatives (17.5% of customers):**\n",
        "- Focus on quality-driven, educational marketing content\n",
        "- Offer detailed product information and expert consultations\n",
        "- Implement targeted email campaigns emphasizing value and durability\n",
        "- Create exclusive shopping hours for a more curated experience\n",
        "\n",
        "**Budget Conservatives (11.5% of customers):**\n",
        "- Limit marketing spend on this group\n",
        "- Emphasize clearance events and promotional pricing\n",
        "- Create early-bird shopping hours for best deals\n",
        "- Focus on practical, necessity-based marketing\n",
        "- Implement simple, straightforward communication strategies\n",
        "\n",
        "## Operational Recommendations\n",
        "\n",
        "### Store Mix and Layout Optimization\n",
        "- **Premium Zone**: Dedicate premium mall spaces to high-end brands targeting Premium Shoppers and high-value Standard Shoppers\n",
        "- **Youth Fashion Hub**: Create a concentrated area for trendy, affordable brands targeting Fashion-Forward Youth\n",
        "- **Value Section**: Ensure adequate representation of discount and outlet stores for Budget Conservatives and price-sensitive segments\n",
        "- **Mixed-Use Areas**: Design spaces that appeal to Standard Shoppers with diverse retail options\n",
        "\n",
        "### Technology Integration\n",
        "- **Mobile App Development**: Create segment-specific app experiences with personalized offers and navigation\n",
        "- **Smart Parking**: Implement dynamic pricing and reserved spaces that reflect customer segments\n",
        "- **Beacon Technology**: Send targeted notifications based on segment profiles and mall location\n",
        "- **Customer Analytics Dashboard**: Track segment performance and shopping patterns in real-time\n",
        "\n",
        "### Staff Training and Service Delivery\n",
        "- **Segment Recognition Training**: Educate staff to identify and appropriately serve different customer segments\n",
        "- **Service Level Differentiation**: Implement varying service approaches based on segment needs and expectations\n",
        "- **Upselling Strategies**: Train staff on segment-appropriate cross-selling and upselling techniques\n",
        "\n",
        "## Performance Measurement and Optimization\n",
        "\n",
        "### Key Performance Indicators (KPIs) by Segment\n",
        "**Revenue Metrics:**\n",
        "- Revenue per customer by segment\n",
        "- Average transaction value by segment\n",
        "- Conversion rate from visits to purchases\n",
        "- Segment-specific profit margins\n",
        "\n",
        "**Engagement Metrics:**\n",
        "- Visit frequency by segment\n",
        "- Time spent in mall by segment\n",
        "- Cross-store shopping behavior\n",
        "- Loyalty program participation rates\n",
        "\n",
        "**Marketing Effectiveness:**\n",
        "- Campaign response rates by segment\n",
        "- Cost per acquisition by segment\n",
        "- Customer lifetime value by segment\n",
        "- Digital engagement rates by segment\n",
        "\n",
        "### A/B Testing Framework\n",
        "- **Promotional Strategies**: Test different discount structures and promotional timing across segments\n",
        "- **Communication Channels**: Compare email, SMS, social media, and in-mall advertising effectiveness\n",
        "- **Service Approaches**: Test personalized vs. standardized service delivery for different segments\n",
        "- **Product Mix**: Experiment with different store combinations and product offerings\n",
        "\n",
        "## Long-term Strategic Considerations\n",
        "\n",
        "### Segment Evolution Monitoring\n",
        "- **Age Progression**: Track how Fashion-Forward Youth transition to other segments over time\n",
        "- **Economic Changes**: Monitor how economic conditions affect segment behavior and size\n",
        "- **Seasonal Variations**: Understand how segments behave differently across seasons and holidays\n",
        "- **Competitive Response**: Analyze how segment preferences shift due to competitor actions\n",
        "\n",
        "### Investment and Expansion Decisions\n",
        "- **New Store Recruitment**: Use segment analysis to identify optimal new retailers and brands\n",
        "- **Renovation Priorities**: Allocate capital improvements based on segment value and specific needs\n",
        "- **Technology Investments**: Prioritize tech solutions that serve high-value segments most effectively\n",
        "- **Marketing Budget Allocation**: Distribute marketing spend proportional to segment value and responsiveness\n",
        "\n",
        "### Risk Management\n",
        "- **Segment Concentration Risk**: Monitor over-dependence on any single customer segment for revenue\n",
        "- **Economic Sensitivity**: Prepare contingency plans for economic downturns affecting different segments\n",
        "- **Demographic Shifts**: Plan for changing community demographics and their impact on segment composition\n",
        "- **Competitive Threats**: Develop retention strategies for high-value segments against competitive pressure\n"
      ],
      "metadata": {
        "id": "dubHmJkuoId5"
      },
      "id": "dubHmJkuoId5"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r1dZXFm3otZx"
      },
      "id": "r1dZXFm3otZx",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}